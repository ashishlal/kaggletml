{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from trackml.dataset import load_event, load_dataset\n",
    "from trackml.score import score_event\n",
    "from trackml.randomize import shuffle_hits\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import hdbscan as _hdbscan\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.cluster.dbscan_ import dbscan\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "import hdbscan\n",
    "# https://www.ellicium.com/python-multiprocessing-pool-process/\n",
    "# http://sebastianraschka.com/Articles/2014_multiprocessing.html\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import hdbscan as _hdbscan\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_event_submission(event_id, hits, labels):\n",
    "    sub_data = np.column_stack(([event_id]*len(hits), hits.hit_id.values, labels))\n",
    "    submission = pd.DataFrame(data=sub_data, columns=[\"event_id\", \"hit_id\", \"track_id\"]).astype(int)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(hits):        \n",
    "    x = hits.x.values\n",
    "    y = hits.y.values\n",
    "    z = hits.z.values\n",
    "\n",
    "    r = np.sqrt(x**2 + y**2 + z**2)\n",
    "    hits['x2'] = x/r\n",
    "    hits['y2'] = y/r\n",
    "\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    hits['z2'] = z/r\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    X = ss.fit_transform(hits[['x2', 'y2', 'z2']].values)\n",
    "#     for i, rz_scale in enumerate(self.rz_scales):\n",
    "#         X[:,i] = X[:,i] * rz_scale\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "#------------------------------------------------------\n",
    "\n",
    "def make_counts(labels):\n",
    "    \n",
    "    \n",
    "    _,reverse,count = np.unique(labels,return_counts=True,return_inverse=True)\n",
    "    counts = count[reverse]\n",
    "    counts[labels==0]=0\n",
    "    \n",
    "    return counts\n",
    "\n",
    "def one_loop(param):\n",
    "    \n",
    "    # <todo> tune your parameters or design your own features here! \n",
    "    \n",
    "    i,m, x,y,z, d,r, a, a_start,a_step = param\n",
    "    #print('\\r %3d  %+0.8f '%(i,da), end='', flush=True)\n",
    "    \n",
    "    da = m*(a_start - (i*a_step))\n",
    "    aa = a + np.sign(z)*z*da \n",
    "    zr = z/r\n",
    "    \n",
    "    X = StandardScaler().fit_transform(np.column_stack([aa, aa/zr, zr, 1/zr, aa/zr + 1/zr]))\n",
    "    _,l = dbscan(X, eps=0.0035, min_samples=1,)\n",
    "\n",
    "    return l\n",
    "\n",
    "def one_loop1(param):\n",
    "    \n",
    "    # <todo> tune your parameters or design your own features here! \n",
    "    \n",
    "    i,m, x,y,z, d,r,r2,z2, w1, w2, w3, a, a_start,a_step = param\n",
    "    #print('\\r %3d  %+0.8f '%(i,da), end='', flush=True)\n",
    "    \n",
    "    da = m*(a_start - (i*a_step))\n",
    "    aa = a + np.sign(z)*z*da\n",
    "    \n",
    "#     if m == 1:\n",
    "#         print(da)\n",
    "    \n",
    "    z1 = z/r\n",
    "    z2 = z/d\n",
    "    \n",
    "    zr = z/r # this is cot(theta), 1/zr is tan(theta)\n",
    "    theta = np.arctan2(r, z)\n",
    "    ct = np.cos(theta)\n",
    "    st = np.sin(theta)\n",
    "    tt = np.tan(theta)\n",
    "#     ctt = np.cot(theta)\n",
    "    z2r = z2/r\n",
    "    z2r2 = z2/r2\n",
    "#     X = StandardScaler().fit_transform(df[['r2', 'theta_1', 'dip_angle', 'z2', 'z2_1', 'z2_2']].values)\n",
    "\n",
    "    caa = np.cos(aa)\n",
    "    saa = np.sin(aa)\n",
    "    taa = np.tan(aa)\n",
    "    ctaa = 1/taa\n",
    "    \n",
    "#     0.000005\n",
    "    deps = 0.0000025\n",
    "#     X = StandardScaler().fit_transform(np.column_stack([caa, saa, tt, 1/tt]))\n",
    "    X = StandardScaler().fit_transform(np.column_stack([caa, saa, z1, z2]))\n",
    "    cx = [w1,w1,w2,w3]\n",
    "    for jj in range(1,X.shape[1]): \n",
    "         X[:,jj] = X[:,jj]*cx[jj]\n",
    "#     l= DBSCAN(eps=0.0035+i*deps,min_samples=1,metric='euclidean',n_jobs=8).fit(X).labels_\n",
    "    _,l = dbscan(X, eps=0.0035, min_samples=1,algorithm='auto')\n",
    "    \n",
    "    return l\n",
    "\n",
    "def one_loop2(param):\n",
    "    \n",
    "    # <todo> tune your parameters or design your own features here! \n",
    "    \n",
    "    i,m, x,y,z, d,r,r2,z2, a, a_start,a_step = param\n",
    "    #print('\\r %3d  %+0.8f '%(i,da), end='', flush=True)\n",
    "    \n",
    "    da = m*(a_start - (i*a_step))\n",
    "    aa = a + np.sign(z)*z*da\n",
    "#     if m == 1:\n",
    "#         print(da)\n",
    "    zr = z/r # this is cot(theta), 1/zr is tan(theta)\n",
    "    theta = np.arctan2(r, z)\n",
    "    ct = np.cos(theta)\n",
    "    st = np.sin(theta)\n",
    "    tt = np.tan(theta)\n",
    "#     ctt = np.cot(theta)\n",
    "    z2r = z2/r\n",
    "    z2r2 = z2/r2\n",
    "#     X = StandardScaler().fit_transform(df[['r2', 'theta_1', 'dip_angle', 'z2', 'z2_1', 'z2_2']].values)\n",
    "\n",
    "    caa = np.cos(aa)\n",
    "    saa = np.sin(aa)\n",
    "    taa = np.tan(aa)\n",
    "    ctaa = 1/taa\n",
    "    \n",
    "#     0.000005\n",
    "    deps = 0.0000025\n",
    "    X = StandardScaler().fit_transform(np.column_stack([caa, saa, tt, 1/tt]))\n",
    "    l= DBSCAN(eps=0.0035+i*deps,min_samples=1,metric='euclidean',n_jobs=8).fit(X).labels_\n",
    "#     _,l = dbscan(X, eps=0.0035, min_samples=1,algorithm='auto')\n",
    "    \n",
    "    return l\n",
    "\n",
    "def do_dbscan_predict(df, w1, w2, w3, Niter):\n",
    "    x  = df.x.values\n",
    "    y  = df.y.values\n",
    "    z  = df.z.values\n",
    "    r  = np.sqrt(x**2+y**2)\n",
    "    d  = np.sqrt(x**2+y**2+z**2)\n",
    "    a  = np.arctan2(y,x)\n",
    "#     a = np.arctan2(z, r)\n",
    "    \n",
    "    x2 = df['x']/d\n",
    "    y2 = df['y']/d\n",
    "    z2 = df['z']/r\n",
    "    \n",
    "    r2 = np.sqrt(x2**2 + y2**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    phi_deg= np.degrees(np.arctan2(y, x))\n",
    "    phi2 = np.arctan2(y2, x2)\n",
    "    phi2_deg = np.degrees(np.arctan2(y2, x2))\n",
    "\n",
    "    theta= np.arctan2(r, z)\n",
    "    theta1 = np.arctan2(r2, z2)\n",
    "\n",
    "    \n",
    "    tan_dip = phi/theta\n",
    "    tan_dip1 = phi/z2\n",
    "    z2_1 = 1/z2\n",
    "    z2_2 = phi/z2 + 1/z2\n",
    "    \n",
    "    dip_angle = np.arctan2(z2, (np.sqrt(x2**2 +y2**2)) * np.arccos(x2/np.sqrt(x2**2 + y2**2)))\n",
    "    dip_angle1 = np.arctan2(z, (np.sqrt(x**2 +y**2)) * np.arccos(x2/np.sqrt(x**2 + y**2)))\n",
    "    scores = []\n",
    "\n",
    "    a_start,a_step,a_num = 0.00100,0.0000095,150\n",
    "    \n",
    "    \n",
    "    a_num = Niter.astype(np.int32)\n",
    "    params  = [(i,m, x,y,z,d,r,r2,z2, w1, w2, w3, a, a_start,a_step) for i in range(a_num) for m in [-1,1]]\n",
    "\n",
    "    if 1: \n",
    "        pool = Pool(processes=1)\n",
    "        ls   = pool.map( one_loop1, params )\n",
    "\n",
    "\n",
    "    if 0:\n",
    "        ls = [ one_loop(param) for param in  params ]\n",
    "\n",
    "\n",
    "    ##------------------------------------------------\n",
    "\n",
    "    num_hits=len(df)\n",
    "    labels = np.zeros(num_hits,np.int32)\n",
    "    counts = np.zeros(num_hits,np.int32)\n",
    "    for l in ls:\n",
    "        c = make_counts(l)\n",
    "        idx = np.where((c-counts>0) & (c<20))[0]\n",
    "        labels[idx] = l[idx] + labels.max()\n",
    "        counts = make_counts(labels)\n",
    "       \n",
    "    \n",
    "#     cl = hdbscan.HDBSCAN(min_samples=1,min_cluster_size=7,\n",
    "#                          metric='braycurtis',cluster_selection_method='leaf',algorithm='best', \n",
    "#                          leaf_size=50)\n",
    "    \n",
    "#     X = preprocess(df)\n",
    "#     l1 = pd.Series(labels)\n",
    "#     labels = np.unique(l1)\n",
    "   \n",
    "# #   print(X.shape)\n",
    "# #   print(len(labels_org))\n",
    "# #   print(len(labels_org[labels_org ==0]))\n",
    "# #   print(len(labels_org[labels_org ==-1]))\n",
    "    \n",
    "#     n_labels = 0\n",
    "#     while n_labels < len(labels):\n",
    "#         n_labels = len(labels)\n",
    "#         max_len = np.max(l1)\n",
    "#         s = list(l1[l1 == 0].keys())\n",
    "#         X = X[s]\n",
    "#         print(X.shape)\n",
    "#         if X.shape[0] <= 1:\n",
    "#             break\n",
    "#         l = cl.fit_predict(X)+max_len\n",
    "# #         print(len(l))\n",
    "#         l1[l1 == 0] = l\n",
    "#         labels = np.unique(l1)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "## reference----------------------------------------------\n",
    "def do_dbscan0_predict(df):\n",
    "    x = df.x.values\n",
    "    y = df.y.values\n",
    "    z = df.z.values\n",
    "    r = np.sqrt(x**2+y**2)\n",
    "    d = np.sqrt(x**2+y**2+z**2)\n",
    "\n",
    "    X = StandardScaler().fit_transform(np.column_stack([\n",
    "        x/d, y/d, z/r]))\n",
    "    _,labels = dbscan(X,\n",
    "                eps=0.0075,\n",
    "                min_samples=1,\n",
    "                algorithm='auto',\n",
    "                n_jobs=-1)\n",
    "\n",
    "    #labels = hdbscan(X, min_samples=1, min_cluster_size=5, cluster_selection_method='eom')\n",
    "\n",
    "    return labels\n",
    "\n",
    "## reference----------------------------------------------\n",
    "def do_dbscan0_predict(df):\n",
    "    x = df.x.values\n",
    "    y = df.y.values\n",
    "    z = df.z.values\n",
    "    r = np.sqrt(x**2+y**2)\n",
    "    d = np.sqrt(x**2+y**2+z**2)\n",
    "\n",
    "    X = StandardScaler().fit_transform(np.column_stack([\n",
    "        x/d, y/d, z/r]))\n",
    "    _,labels = dbscan(X,\n",
    "                eps=0.0075,\n",
    "                min_samples=1,\n",
    "                algorithm='auto',\n",
    "                n_jobs=-1)\n",
    "\n",
    "    #labels = hdbscan(X, min_samples=1, min_cluster_size=5, cluster_selection_method='eom')\n",
    "\n",
    "    return labels\n",
    "\n",
    "def extend(submission,hits):\n",
    "    df = submission.merge(hits,  on=['hit_id'], how='left')\n",
    "#     df = submission.append(hits)\n",
    "#     print(df.head())\n",
    "    df = df.assign(d = np.sqrt( df.x**2 + df.y**2 + df.z**2 ))\n",
    "    df = df.assign(r = np.sqrt( df.x**2 + df.y**2))\n",
    "    df = df.assign(arctan2 = np.arctan2(df.z, df.r))\n",
    "\n",
    "    for angle in range(-180,180,1):\n",
    "\n",
    "        print ('\\r %f'%angle, end='',flush=True)\n",
    "        #df1 = df.loc[(df.arctan2>(angle-0.5)/180*np.pi) & (df.arctan2<(angle+0.5)/180*np.pi)]\n",
    "        df1 = df.loc[(df.arctan2>(angle-1.0)/180*np.pi) & (df.arctan2<(angle+1.0)/180*np.pi)]\n",
    "\n",
    "        min_num_neighbours = len(df1)\n",
    "        if min_num_neighbours<4: continue\n",
    "\n",
    "        hit_ids = df1.hit_id.values\n",
    "        x,y,z = df1.as_matrix(columns=['x', 'y', 'z']).T\n",
    "        r  = (x**2 + y**2)**0.5\n",
    "        r  = r/1000\n",
    "        a  = np.arctan2(y,x)\n",
    "        tree = KDTree(np.column_stack([a,r]), metric='euclidean')\n",
    "\n",
    "        track_ids = list(df1.track_id.unique())\n",
    "        num_track_ids = len(track_ids)\n",
    "        min_length=3\n",
    "\n",
    "        for i in range(num_track_ids):\n",
    "            p = track_ids[i]\n",
    "            if p==0: continue\n",
    "\n",
    "            idx = np.where(df1.track_id==p)[0]\n",
    "            if len(idx)<min_length: continue\n",
    "\n",
    "            if angle>0:\n",
    "                idx = idx[np.argsort( z[idx])]\n",
    "            else:\n",
    "                idx = idx[np.argsort(-z[idx])]\n",
    "\n",
    "\n",
    "            ## start and end points  ##\n",
    "            idx0,idx1 = idx[0],idx[-1]\n",
    "            a0 = a[idx0]\n",
    "            a1 = a[idx1]\n",
    "            r0 = r[idx0]\n",
    "            r1 = r[idx1]\n",
    "\n",
    "            da0 = a[idx[1]] - a[idx[0]]  #direction\n",
    "            dr0 = r[idx[1]] - r[idx[0]]\n",
    "            direction0 = np.arctan2(dr0,da0) \n",
    "\n",
    "            da1 = a[idx[-1]] - a[idx[-2]]\n",
    "            dr1 = r[idx[-1]] - r[idx[-2]]\n",
    "            direction1 = np.arctan2(dr1,da1) \n",
    "\n",
    "\n",
    "            ## extend start point\n",
    "            ns = tree.query([[a0,r0]], k=min(20,min_num_neighbours), return_distance=False)\n",
    "            ns = np.concatenate(ns)\n",
    "            direction = np.arctan2(r0-r[ns],a0-a[ns])\n",
    "            ns = ns[(r0-r[ns]>0.01) &(np.fabs(direction-direction0)<0.04)]\n",
    "\n",
    "            for n in ns:\n",
    "                df.loc[ df.hit_id==hit_ids[n],'track_id' ] = p \n",
    "\n",
    "            ## extend end point\n",
    "            ns = tree.query([[a1,r1]], k=min(20,min_num_neighbours), return_distance=False)\n",
    "            ns = np.concatenate(ns)\n",
    "\n",
    "            direction = np.arctan2(r[ns]-r1,a[ns]-a1)\n",
    "            ns = ns[(r[ns]-r1>0.01) &(np.fabs(direction-direction1)<0.04)] \n",
    "\n",
    "            for n in ns:\n",
    "                df.loc[ df.hit_id==hit_ids[n],'track_id' ] = p\n",
    "    #print ('\\r')\n",
    "#     df = df[['particle_id', 'weight', 'event_id', 'hit_id', 'track_id']]\n",
    "    df = df[['event_id', 'hit_id', 'track_id']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fun4BO(w1,w2,w3,Niter):\n",
    "    track_id = do_dbscan_predict(hits, w1,w2,w3,Niter)\n",
    "#     track_id = do_dbscan_predict2(hits)\n",
    "    sum_score=0\n",
    "    sum = 0\n",
    "    submission = pd.DataFrame(columns=['event_id', 'hit_id', 'track_id'],\n",
    "        data=np.column_stack(([int(event_id),]*len(hits), hits.hit_id.values, track_id))\n",
    "    ).astype(int)\n",
    "    for i in range(2):\n",
    "        submission = extend(submission,hits)\n",
    "        score = score_event(truth, submission)\n",
    "        print('[%2d] score : %0.8f'%(i, score))\n",
    "        sum_score += score\n",
    "        sum += 1\n",
    "\n",
    "    print('--------------------------------------')\n",
    "    sc = sum_score/sum\n",
    "    print(sc)\n",
    "    \n",
    "    return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     Niter |        w1 |        w2 |        w3 | \n",
      " 179.0000000[ 0] score : 0.51318437\n",
      " 179.0000000[ 1] score : 0.51721947\n",
      "--------------------------------------\n",
      "0.5152019205697601\n",
      "    1 | 05m23s | \u001b[35m   0.51520\u001b[0m | \u001b[32m 154.5319\u001b[0m | \u001b[32m   1.1820\u001b[0m | \u001b[32m   0.6159\u001b[0m | \u001b[32m   0.1013\u001b[0m | \n",
      " 179.0000000[ 0] score : 0.51814982\n",
      " 179.0000000[ 1] score : 0.52142011\n",
      "--------------------------------------\n",
      "0.5197849648342838\n",
      "    2 | 05m02s | \u001b[35m   0.51978\u001b[0m | \u001b[32m 145.5130\u001b[0m | \u001b[32m   0.9940\u001b[0m | \u001b[32m   0.5367\u001b[0m | \u001b[32m   0.1956\u001b[0m | \n",
      " 179.0000000[ 0] score : 0.51799722\n",
      " 179.0000000[ 1] score : 0.52263257\n",
      "--------------------------------------\n",
      "0.5203148944415414\n",
      "    3 | 06m02s | \u001b[35m   0.52031\u001b[0m | \u001b[32m 177.2357\u001b[0m | \u001b[32m   1.0440\u001b[0m | \u001b[32m   0.5970\u001b[0m | \u001b[32m   0.3689\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     Niter |        w1 |        w2 |        w3 | \n",
      " 179.0000000[ 0] score : 0.50898864\n",
      " 179.0000000[ 1] score : 0.51389075\n",
      "--------------------------------------\n",
      "0.511439693558733\n",
      "    4 | 06m36s |    0.51144 |  189.9992 |    1.1317 |    0.6830 |    0.1116 | \n",
      " 179.0000000[ 0] score : 0.51997025\n",
      " 179.0000000[ 1] score : 0.52380415\n",
      "--------------------------------------\n",
      "0.5218872010682394\n",
      "    5 | 04m55s | \u001b[35m   0.52189\u001b[0m | \u001b[32m 140.0298\u001b[0m | \u001b[32m   1.1978\u001b[0m | \u001b[32m   0.3514\u001b[0m | \u001b[32m   0.3881\u001b[0m | \n",
      " 179.0000000[ 0] score : 0.50839999\n",
      " 179.0000000[ 1] score : 0.51195638\n",
      "--------------------------------------\n",
      "0.5101781856033589\n",
      "    6 | 05m16s |    0.51018 |  140.0062 |    0.9190 |    0.6542 |    0.1213 | \n",
      " 179.0000000[ 0] score : 0.50292558\n",
      " 179.0000000[ 1] score : 0.50774411\n",
      "--------------------------------------\n",
      "0.5053348428177263\n",
      "    7 | 05m39s |    0.50533 |  167.0813 |    0.9000 |    0.3000 |    0.4000 | \n",
      " 179.0000000[ 0] score : 0.50784314\n",
      " 179.0000000[ 1] score : 0.51200354\n",
      "--------------------------------------\n",
      "0.5099233438822734\n",
      "    8 | 06m00s |    0.50992 |  182.9300 |    1.2000 |    0.3000 |    0.4000 | \n",
      " 179.0000000[ 0] score : 0.51126667\n",
      " 179.0000000[ 1] score : 0.51535670\n",
      "--------------------------------------\n",
      "0.5133116835167078\n",
      "    9 | 05m18s |    0.51331 |  147.2367 |    1.2000 |    0.7000 |    0.4000 | \n",
      " 179.0000000[ 0] score : 0.46930155\n",
      " 179.0000000[ 1] score : 0.47567927\n",
      "--------------------------------------\n",
      "0.4724904097628091\n",
      "   10 | 06m03s |    0.47249 |  173.5090 |    1.1866 |    0.3218 |    0.1057 | \n",
      " 179.0000000[ 0] score : 0.51136777\n",
      " 179.0000000[ 1] score : 0.51619039\n",
      "--------------------------------------\n",
      "0.5137790820986989\n",
      "   11 | 05m46s |    0.51378 |  160.2638 |    0.9000 |    0.7000 |    0.4000 | \n",
      " 179.0000000[ 0] score : 0.51022003\n",
      " 179.0000000[ 1] score : 0.51488202\n",
      "--------------------------------------\n",
      "0.5125510277934673\n",
      "   12 | 05m15s |    0.51255 |  151.7544 |    0.9000 |    0.3000 |    0.4000 | \n",
      " 179.0000000[ 0] score : 0.50090283\n",
      " 179.0000000[ 1] score : 0.50542354\n",
      "--------------------------------------\n",
      "0.5031631872434752\n",
      "   13 | 06m15s |    0.50316 |  181.6590 |    0.9000 |    0.7000 |    0.1000 | \n",
      " 179.0000000[ 0] score : 0.49470712\n",
      " 179.0000000[ 1] score : 0.49890594\n",
      "--------------------------------------\n",
      "0.49680652755139576\n",
      "   14 | 06m17s |    0.49681 |  189.8391 |    0.9000 |    0.3000 |    0.4000 | \n",
      " 179.0000000[ 0] score : 0.51057201\n",
      " 179.0000000[ 1] score : 0.51539633\n",
      "--------------------------------------\n",
      "0.5129841704203125\n",
      "   15 | 06m19s |    0.51298 |  186.7939 |    1.2000 |    0.7000 |    0.4000 | \n",
      " 179.0000000[ 0] score : 0.51264851\n",
      " 179.0000000[ 1] score : 0.51673909\n",
      "--------------------------------------\n",
      "0.5146938023475955\n",
      "   16 | 05m29s |    0.51469 |  162.9601 |    1.2000 |    0.3000 |    0.4000 | \n",
      " 179.0000000[ 0] score : 0.51023361\n",
      " 179.0000000[ 1] score : 0.51508081\n",
      "--------------------------------------\n",
      "0.5126572082439196\n",
      "   17 | 06m06s |    0.51266 |  179.7227 |    1.2000 |    0.7000 |    0.4000 | \n",
      " 179.0000000[ 0] score : 0.51107703\n",
      " 179.0000000[ 1] score : 0.51599157\n",
      "--------------------------------------\n",
      "0.5135343028176561\n",
      "   18 | 05m08s |    0.51353 |  142.7917 |    1.2000 |    0.7000 |    0.4000 | \n",
      " 179.0000000[ 0] score : 0.50624748\n",
      " 179.0000000[ 1] score : 0.51133394\n",
      "--------------------------------------\n",
      "0.5087907135674483\n",
      "   19 | 05m25s |    0.50879 |  157.0615 |    0.9268 |    0.3000 |    0.4000 | \n",
      " 179.0000000[ 0] score : 0.47472044\n",
      " 179.0000000[ 1] score : 0.48168650\n",
      "--------------------------------------\n",
      "0.47820346813714676\n",
      "   20 | 05m04s |    0.47820 |  142.2474 |    1.2000 |    0.3000 |    0.1000 | \n",
      " 179.0000000[ 0] score : 0.50302604\n",
      " 179.0000000[ 1] score : 0.50761679\n",
      "--------------------------------------\n",
      "0.5053214170876692\n",
      "   21 | 05m45s |    0.50532 |  164.3813 |    0.9000 |    0.7000 |    0.1000 | \n",
      " 179.0000000[ 0] score : 0.51058884\n",
      " 179.0000000[ 1] score : 0.51607306\n",
      "--------------------------------------\n",
      "0.5133309486567899\n",
      "   22 | 05m27s |    0.51333 |  154.3174 |    0.9000 |    0.7000 |    0.4000 | \n",
      " 179.0000000[ 0] score : 0.45023502\n",
      " 179.0000000[ 1] score : 0.45589176\n",
      "--------------------------------------\n",
      "0.45306339074005\n",
      "   23 | 06m09s |    0.45306 |  178.3720 |    1.2000 |    0.3000 |    0.1000 | \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#########################################\n",
    "\n",
    "# def run_dbscan():\n",
    "\n",
    "data_dir = '../data/train'\n",
    "\n",
    "#     event_ids = [\n",
    "#             '000001030',##\n",
    "#             '000001025','000001026','000001027','000001028','000001029',\n",
    "#     ]\n",
    "\n",
    "event_ids = [\n",
    "        '000001030',##\n",
    "\n",
    "]\n",
    "\n",
    "sum=0\n",
    "sum_score=0\n",
    "for i,event_id in enumerate(event_ids):\n",
    "    particles = pd.read_csv(data_dir + '/event%s-particles.csv'%event_id)\n",
    "    hits  = pd.read_csv(data_dir + '/event%s-hits.csv'%event_id)\n",
    "    cells = pd.read_csv(data_dir + '/event%s-cells.csv'%event_id)\n",
    "    truth = pd.read_csv(data_dir + '/event%s-truth.csv'%event_id)\n",
    "    particles = pd.read_csv(data_dir + '/event%s-particles.csv'%event_id)\n",
    "    \n",
    "    truth = pd.merge(truth, particles, how='left', on='particle_id')\n",
    "    hits = pd.merge(hits, truth, how='left', on='hit_id')\n",
    "\n",
    "#     hits = hits[hits.particle_id != 0]\n",
    "    w1 = [0.9, 1.2]\n",
    "    w2 = [0.3, 0.7]\n",
    "    w3 = [0.1, 0.4]\n",
    "    Niter = [140, 190]\n",
    "    \n",
    "    \n",
    "    bo = BayesianOptimization(Fun4BO,pbounds = {'w1':w1,'w2':w2,'w3':w3,'Niter':Niter})\n",
    "    bo.maximize(init_points = 3, n_iter = 20, acq = \"ucb\", kappa = 2.576)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 179.0000000[ 0] score : 0.49409776\n",
      " 179.0000000[ 1] score : 0.49873591\n",
      " 179.0000000[ 2] score : 0.50057185\n",
      " 179.0000000[ 3] score : 0.50147617\n",
      " 179.0000000[ 4] score : 0.50191906\n",
      " 179.0000000[ 5] score : 0.50177841\n",
      " 179.0000000[ 6] score : 0.50144026\n",
      " 179.0000000[ 7] score : 0.50175792\n",
      "--------------------------------------\n",
      "0.5002221667884463\n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "\n",
    "# def run_dbscan():\n",
    "\n",
    "data_dir = '../data/train'\n",
    "\n",
    "#     event_ids = [\n",
    "#             '000001030',##\n",
    "#             '000001025','000001026','000001027','000001028','000001029',\n",
    "#     ]\n",
    "\n",
    "event_ids = [\n",
    "        '000001030',##\n",
    "\n",
    "]\n",
    "\n",
    "sum=0\n",
    "sum_score=0\n",
    "for i,event_id in enumerate(event_ids):\n",
    "    particles = pd.read_csv(data_dir + '/event%s-particles.csv'%event_id)\n",
    "    hits  = pd.read_csv(data_dir + '/event%s-hits.csv'%event_id)\n",
    "    cells = pd.read_csv(data_dir + '/event%s-cells.csv'%event_id)\n",
    "    truth = pd.read_csv(data_dir + '/event%s-truth.csv'%event_id)\n",
    "    particles = pd.read_csv(data_dir + '/event%s-particles.csv'%event_id)\n",
    "    \n",
    "    truth = pd.merge(truth, particles, how='left', on='particle_id')\n",
    "    hits = pd.merge(hits, truth, how='left', on='hit_id')\n",
    "\n",
    "#     hits = hits[hits.particle_id != 0]\n",
    "    w1 = [0.9, 1.2]\n",
    "    w2 = [0.3, 0.7]\n",
    "    w3 = [0.1, 0.4]\n",
    "    Niter = [140, 190]\n",
    "    \n",
    "    \n",
    "    bo = BayesianOptimization(Fun4BO,pbounds = {'w1':w1,'w2':w2,'w3':w3,'Niter':Niter})\n",
    "    bo.maximize(init_points = 3, n_iter = 20, acq = \"ucb\", kappa = 2.576)\n",
    "    \n",
    "    track_id = do_dbscan_predict(hits)\n",
    "\n",
    "    submission = pd.DataFrame(columns=['event_id', 'hit_id', 'track_id'],\n",
    "        data=np.column_stack(([int(event_id),]*len(hits), hits.hit_id.values, track_id))\n",
    "    ).astype(int)\n",
    "    for i in range(8):\n",
    "        submission = extend(submission,hits)\n",
    "        score = score_event(truth, submission)\n",
    "        print('[%2d] score : %0.8f'%(i, score))\n",
    "        sum_score += score\n",
    "        sum += 1\n",
    "\n",
    "print('--------------------------------------')\n",
    "print(sum_score/sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_dbscan()\n",
    "# 0.38886407617656094\n",
    "# 0.43999828380439265 after caa, saa\n",
    "# 0.48344805750948866 after extend\n",
    "# 0.4835126378397637 after removing aa/zr + 1/zr\n",
    "# with z2 goes down to 0.45\n",
    "# with r2 goes down to 0.40\n",
    "# with 1/r2 down to 0.43\n",
    "# with 1/r2 and theta down to 0.41\n",
    "# with 1/r2 and 1/theta down to 0.41\n",
    "# 0.13 with phi2\n",
    "# 0.417 with 1/phi2\n",
    "# 0.436 with tan_dip1\n",
    "# 0.422 with 1/tan_dip1\n",
    "# 0.434 with z2r2 and z2r2 and 1/z2r2\n",
    "# 0.334 if zr is replaced with z2r2\n",
    "# 0.4888877339626617 if aa/zr replaced with caa/zr\n",
    "# 0.4887566511321033 if aa/zr if replaces with saa/zr\n",
    "# 0.4895407603454436 if aa/zr is removed ( only caa, saa, zr, 1/zr remains)\n",
    "# 0.48876599546214305 with 0.0038 instead of 0.0035\n",
    "# 0.48769542639758245 if remove 1/zr\n",
    "# 0.0 if both zr and 1/zr are removed\n",
    "# 0.44026470041552757 if ct, st are added\n",
    "# 0.21311494225786964 if only caa, saa, ct\n",
    "# 0.40320264914764326 if only caa, saa, st\n",
    "# 0.3773604786775556 if only caa, saa, st, 1/st\n",
    "# 0.4895407603454436 if only caa, saa, tt, 1/tt\n",
    "# 0.13480299643426075 if only taa, 1/taa, tt, 1/tt\n",
    "# 0.0885347888971582 if only taa, 1/taa, ct, st\n",
    "# 0.04670868936897901 if only taa, ct, st\n",
    "# 0.025523671048730837 if only taa and st\n",
    "# 0.025057657406745617 if only 1/taa, st\n",
    "# 0.5025429199508328 caa, saa, tt, 1/tt  when particle_id != 0\n",
    "# 0.4909138125112928 with deps=0.000005\n",
    "# 0.4884101555506272 with deps=0.000010\n",
    "# 0.49112882444220873 with deps=0.0000025\n",
    "# 0.4903305156288079 with deps=0.0000021\n",
    "# 0.4900532530976269 with deps=0.0000022\n",
    "# 0.4908567128710496 with deps=0.0000023\n",
    "# 0.4906372351101146 with deps=0.0000024\n",
    "# 0.49066011553021205 with deps=0.0000026\n",
    "# 0.4907583816106307 with deps=0.0000027\n",
    "# 0.49015657761806697 with deps=0.0000028\n",
    "# 0.49027772717858303 with deps=0.0000029\n",
    "# 0.48968636878606386 wih deps=0.00000025\n",
    "# 0.48868485370179743 with 180 steps\n",
    "# 0.4922564475970125 with 170 steps\n",
    "# 0.4931891169309856 with 160 steps\n",
    "# 0.4940977643648564 with 150 steps\n",
    "# 0.4905422457697099 with 140 steps\n",
    "# 0.49255846616829907 with 130 steps\n",
    "# 0.4886465357416342 with 120 steps\n",
    "# 0.3215078003096232 with 110 steps\n",
    "# 0.49279218495929467 with 155 steps\n",
    "# 0.4918913043654569 with 145 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'track_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b25af2ee21af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrack_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'track_id' is not defined"
     ]
    }
   ],
   "source": [
    "track_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   0,    1,    2,    4,    5,   19,   34,   56, 7777, 9822]), array([1, 2, 0, 3, 4, 5, 6, 7, 2, 3, 8, 4, 9, 5, 0, 2, 1]), array([2, 2, 3, 2, 2, 2, 1, 1, 1, 1]))\n"
     ]
    }
   ],
   "source": [
    "l = pd.Series([1,2,0,4,5,19,34,56,2,4,7777,5, 9822, 19, 0, 2, 1])\n",
    "print(np.unique(l, return_counts=True, return_inverse=True))\n",
    "_, reverse, count = np.unique(l, return_counts=True, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 2 2 2 2 1 1 3 2 1 2 1 2 2 3 2]\n"
     ]
    }
   ],
   "source": [
    "counts = count[reverse]\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(l).count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, 2, 2, 2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2, 14]),)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.array(l)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2, 14]),)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(pd.Series(l)==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2      True\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14     True\n",
       "15    False\n",
       "16    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(l)==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = pd.Series(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[l == 0] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        2\n",
       "2       10\n",
       "3        4\n",
       "4        5\n",
       "5       19\n",
       "6       34\n",
       "7       56\n",
       "8        2\n",
       "9        4\n",
       "10    7777\n",
       "11       5\n",
       "12    9822\n",
       "13      19\n",
       "14      10\n",
       "15       2\n",
       "16       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 10, 4, 5, 19, 34, 56, 2, 4, 7777, 5, 9822, 19, 10, 2, 1]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hits[['x2','y2','z2']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113998, 3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = pd.Series(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = list(l1[l1 == 0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.29421146e-02,  1.77294928e-03, -2.32458407e+01],\n",
       "       [-5.05565632e-02,  7.16865790e-05, -1.97545112e+01]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hits=6\n",
    "labels = np.zeros(num_hits,np.int32)\n",
    "counts = np.zeros(num_hits,np.int32)\n",
    "for l in ls:\n",
    "    c = make_counts(l)\n",
    "    print(len(c))\n",
    "    print(len(l))\n",
    "    idx = np.where((c-counts>0) & (c<20))[0]\n",
    "    labels[idx] = l[idx] + labels.max()\n",
    "    counts = make_counts(labels)\n",
    "    print(len(counts))\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hits=17\n",
    "labels = np.zeros(num_hits,np.int32)\n",
    "counts = np.zeros(num_hits,np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-cde25b5e10ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = make_counts(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 0, 2, 2, 2, 1, 1, 3, 2, 1, 2, 1, 2, 0, 3, 2])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c-counts > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  7, 10, 12])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((c-counts>0) & (c<2))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where((c-counts>0) & (c<2))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[idx] = l[idx] + labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,   34,   56,    0,    0, 7777,\n",
       "          0, 9822,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmlf",
   "language": "python",
   "name": "tmlf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
